{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI Diary\n",
        "This notebook demonstrates:\n",
        "1. Dataset loading and preprocessing\n",
        "2. A domain-specific BERT baseline (ClinicalBERT)\n",
        "3. A transformer-based prototype (RoBERTa)\n",
        "4. Model evaluation and comparison\n",
        "\n",
        "**NOTE:**\n",
        "This is an INTERIM prototype (IPD)\n",
        "Models are trained lightly for feasibility, not optimisation\n"
      ],
      "metadata": {
        "id": "yUDtOB7OXu5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# AI Diary Project — Emotion Detection (IPD)\n",
        "\n",
        "\n",
        "# Core system utilities\n",
        "import os\n",
        "import glob\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Data handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine learning utilities\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Deep learning / NLP\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "\n",
        "# Hugging Face dataset helper\n",
        "from datasets import Dataset\n",
        "\n",
        "# Disable external logging tools\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
      ],
      "metadata": {
        "id": "XxsRrM_VEXaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# Dataset Upload and Extraction\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "zip_path = list(uploaded.keys())[0]\n",
        "os.makedirs(\"goemotions\", exist_ok=True)\n",
        "\n",
        "with ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"goemotions\")\n"
      ],
      "metadata": {
        "id": "GeXpExE-FBvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# Locate and Load Dataset Files\n",
        "\n",
        "\n",
        "def find_file(pattern):\n",
        "    matches = glob.glob(pattern, recursive=True)\n",
        "    if not matches:\n",
        "        raise FileNotFoundError(f\"No file: {pattern}\")\n",
        "    return matches[0]\n",
        "\n",
        "train_path = find_file(\"goemotions/**/train.tsv\")\n",
        "emotions_path = find_file(\"goemotions/**/emotions.txt\")\n",
        "\n",
        "train_df = pd.read_csv(\n",
        "    train_path,\n",
        "    sep=\"\\t\",\n",
        "    names=[\"text\", \"labels\", \"id\"]\n",
        ")\n",
        "\n",
        "with open(emotions_path, encoding=\"utf-8\") as f:\n",
        "    emotions = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "print(\"Samples:\", len(train_df))\n",
        "print(\"Emotion:\", len(emotions))\n"
      ],
      "metadata": {
        "id": "-fpjIiENFKaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# Dataset Subsampling (IPD Justification)\n",
        "\n",
        "\n",
        "train_small = train_df.sample(5000, random_state=42).reset_index(drop=True)\n",
        "NUM_EMOTIONS = len(emotions)\n",
        "\n",
        "print(\"Subset size:\", len(train_small))\n"
      ],
      "metadata": {
        "id": "PaouJzxAFLUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# Label Encoding (Multi-label → Multi-hot)\n",
        "\n",
        "\n",
        "def encode_labels(label_string):\n",
        "    vector = np.zeros(NUM_EMOTIONS)\n",
        "    for label in str(label_string).split(\",\"):\n",
        "        if label.isdigit():\n",
        "            vector[int(label)] = 1\n",
        "    return vector\n",
        "\n",
        "train_small[\"label_vector\"] = train_small[\"labels\"].apply(encode_labels)\n"
      ],
      "metadata": {
        "id": "5rZaiEQKFOXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# Train/Test Split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    train_small[\"text\"],\n",
        "    np.stack(train_small[\"label_vector\"]),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "WYWHBjhcFRzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# Evaluation Metric\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "\n",
        "    # Apply sigmoid to logits\n",
        "    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
        "\n",
        "    # Use LOWER threshold for IPD\n",
        "    predictions = (probs >= 0.3).astype(int)\n",
        "\n",
        "    return {\n",
        "        \"macro_f1\": f1_score(labels, predictions, average=\"macro\", zero_division=0),\n",
        "        \"micro_f1\": f1_score(labels, predictions, average=\"micro\", zero_division=0),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "O9YGyFCgH5Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# Baseline Model — Domain-Specific BERT (ClinicalBERT)\n",
        "\n",
        "\n",
        "CLINICAL_BERT = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "\n",
        "clinical_tokenizer = AutoTokenizer.from_pretrained(CLINICAL_BERT)\n",
        "\n",
        "def tokenize_clinical(batch):\n",
        "    return clinical_tokenizer(\n",
        "        batch[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "clinical_train_ds = Dataset.from_dict({\n",
        "    \"text\": X_train.tolist(),\n",
        "    \"labels\": y_train.tolist()\n",
        "})\n",
        "\n",
        "clinical_test_ds = Dataset.from_dict({\n",
        "    \"text\": X_test.tolist(),\n",
        "    \"labels\": y_test.tolist()\n",
        "})\n",
        "\n",
        "clinical_train_ds = clinical_train_ds.map(tokenize_clinical, batched=True)\n",
        "clinical_test_ds = clinical_test_ds.map(tokenize_clinical, batched=True)\n",
        "\n",
        "clinical_train_ds.set_format(\"torch\")\n",
        "clinical_test_ds.set_format(\"torch\")\n"
      ],
      "metadata": {
        "id": "wpxY8e-oFT2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# ClinicalBERT Model Configuration\n",
        "\n",
        "clinical_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    CLINICAL_BERT,\n",
        "    num_labels=NUM_EMOTIONS,\n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "\n",
        "clinical_args = TrainingArguments(\n",
        "    output_dir=\"clinicalbert_results\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "clinical_trainer = Trainer(\n",
        "    model=clinical_model,\n",
        "    args=clinical_args,\n",
        "    train_dataset=clinical_train_ds,\n",
        "    eval_dataset=clinical_test_ds,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "clinical_trainer.train()\n",
        "clinical_metrics = clinical_trainer.evaluate()\n",
        "\n",
        "print(\"ClinicalBERT Performance:\", clinical_metrics)\n"
      ],
      "metadata": {
        "id": "j5UPBl_OFdKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# Tokenisation using RoBERTa\n",
        "\n",
        "\n",
        "roberta_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "def tokenize_roberta(batch):\n",
        "    return roberta_tokenizer(\n",
        "        batch[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "train_ds = Dataset.from_dict({\"text\": X_train.tolist(), \"labels\": y_train.tolist()})\n",
        "test_ds = Dataset.from_dict({\"text\": X_test.tolist(), \"labels\": y_test.tolist()})\n",
        "\n",
        "train_ds = train_ds.map(tokenize_roberta, batched=True)\n",
        "test_ds = test_ds.map(tokenize_roberta, batched=True)\n",
        "\n",
        "train_ds.set_format(\"torch\")\n",
        "test_ds.set_format(\"torch\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_tv2nqR2FfeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# RoBERTa Model Configuration\n",
        "\n",
        "roberta_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"roberta-base\",\n",
        "    num_labels=NUM_EMOTIONS,\n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "\n",
        "roberta_args = TrainingArguments(\n",
        "    output_dir=\"roberta_results\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "roberta_trainer = Trainer(\n",
        "    model=roberta_model,\n",
        "    args=roberta_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=test_ds,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "roberta_trainer.train()\n",
        "\n",
        "roberta_metrics = roberta_trainer.evaluate()\n",
        "\n",
        "print(\"RoBERTa Performance:\", roberta_metrics)\n"
      ],
      "metadata": {
        "id": "FbXvdWW3FhxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# Model Performance Comparison (Interim Results)\n",
        "\n",
        "\n",
        "models = [\"ClinicalBERT\", \"RoBERTa\"]\n",
        "\n",
        "macro_f1 = [\n",
        "    clinical_metrics[\"eval_macro_f1\"],\n",
        "    roberta_metrics[\"eval_macro_f1\"]\n",
        "]\n",
        "\n",
        "micro_f1 = [\n",
        "    clinical_metrics[\"eval_micro_f1\"],\n",
        "    roberta_metrics[\"eval_micro_f1\"]\n",
        "]\n",
        "\n",
        "x = np.arange(len(models))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "plt.bar(\n",
        "    x - width/2,\n",
        "    macro_f1,\n",
        "    width,\n",
        "    label=\"Macro F1 (Class-balanced)\"\n",
        ")\n",
        "\n",
        "plt.bar(\n",
        "    x + width/2,\n",
        "    micro_f1,\n",
        "    width,\n",
        "    label=\"Micro F1 (Overall)\"\n",
        ")\n",
        "\n",
        "plt.xticks(x, models)\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.title(\n",
        "    \"Performance Comparison (ClinicalBERT and RoBERTa)\"\n",
        ")\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jrXrEU1yFjlv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}